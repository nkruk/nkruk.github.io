---
layout: post
title:  "Code karma, AI's double bind and its poisonous stain"
date:   2025-09-30 17:00:00 +0100s
---

Welcome to my second post with rambling thoughts on AI usage. And remember: The opinions shared here are my own and do not reflect the views of my employer nor the ones of my family, friends, colleagues, or even neighbors.

---

Maybe it's my bad luck but there's a constant in my professional life as a developer: all those tiny-and-not-completely-understood code excerpts (TANCUCEs) that I fish out from StackOverflow (or now from AI generated code) that I've used to cop out of thorny issues have consistently came back to haunt me and bite me in the ass if not sooner then later. I call it code karma.

Code karma has increased significantly in this AI era. Even more TANCUCEs get into production code every day. And worse yet, Copilot is suggesting us TANCUCEs after each new pressed Enter (meaning: even when we are not even actively looking for them). And of course, being the lazy humans we are, we keep pressing Tab.

There's a bit of a double bind going on with AI in programming. A bit of context for all those technical readers without a head rotten by Psychology lectures. Double bind is a beautiful theory created by Gregory Bateson about how can you make someone schizophrenic (Disclaimer: it's only a theory, we don't actually have many certainties about the origins of schizophrenia). So in essence, a double bind happens when a group or individual gets two conflicting demands. Demand 1: use AI tools and AI generated code, develop faster. Demand 2: Be careful, don't push anything you don't understand, don't trade expediency for technical debt/hard to catch bugs.

If I have to dig into every suggested AI excerpt I use then I will start a proper back and forth between me, an AI chat and other web sources. But that's not fast anymore. It's slow and thorough. But then again, when I DO know what I'm doing then I'm much faster doing the thing from scratch or using actual code to generate it (proper templates/live templates/bash scripts/fragments/CLI scaffolds beat AI agents with one arm tied to the back).

Almost a year ago I wrote about AI prospects. Things have improved. In one way or another I use LLMs almost every day, both for work and private life. For example: I would have not been able to pass a pre-university Math course without its help (it? what are your pronouns dear AI Lord?) And I'm really not good in Math so that was quite the acid test. Of course there were also problems. Wrong answers that made me lose hours and hours. An actual mathematician in Reddit sums it up like this:

> I treat it like a mentor / professor during office hours, but the professor has some schizophrenic delusions, where 20% of the time they will say some incoherent nonsense that sounds convincing. 80% of the time they’re helpful. 20% of the time they’re actively leading you in the wrong direction. It’s a net positive in my opinion.

I think this pretty much sums up the state of the art with LLMs (and my personal bet: probably its future prospects).

And here's my final rambling thought. Recently I bumped into what I reckon to be a slice of future tastes. Indie game devs have begun adding a no-generative-AI stamp in their stores or Steam game pages. This could go two ways: either no-AI badges turn into a 'veganism for software' thing OR it could be foreshadowing something more troublesome for AI-aided content.

Think about my experience with Math. I used AI as a crutch. A dirty little secret that we look forward not needing in the future (at least not for the same things). People buy into human connection. We buy into products and services in which the human touch of love is self-evident. Will AI 'features' in products, content and services play the role of a poisonous stain for the consumer?

That's it for now. And yes, maybe I deserve the luddite label. I think it's more than that. Maybe my sustained scepticism simply stems from two dearly held working class beliefs ingrained into my brain: 1) If it's too good to be true, it probably is. 2) Nothing truly good comes easy.

P.S: This post correct grammar or lack-thereof comes courtesy of ChatGPT.